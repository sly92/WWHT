{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for sample Weight\n",
    "# Test With LSTM\n",
    "# Test with shuffle false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from datetime import datetime\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.keras._impl.keras.layers import Dense, Input, LSTM, BatchNormalization, Flatten, TimeDistributed, Dropout, Reshape\n",
    "from tensorflow.python.keras._impl.keras.models import Model\n",
    "from tensorflow.python.keras._impl.keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_divisor(num: int) -> list:\n",
    "    \"\"\"\n",
    "    Return all the divisors of a number\n",
    "    :param num: The number to find the divisors\n",
    "    :return: A list of divisors\n",
    "    \"\"\"\n",
    "    divisor = list()\n",
    "    for i in range(1, num+1):\n",
    "        if num % i == 0:\n",
    "            divisor.append(i)\n",
    "    return divisor\n",
    "\n",
    "\n",
    "def normalize_nums(num: int, minimum: int, maximum: int) -> float:\n",
    "    \"\"\"\n",
    "    Normalize a positive integer between 0 and 1\n",
    "    :param num: The num to normalize\n",
    "    :param minimum: The maximum range\n",
    "    :param maximum:  The minimum range\n",
    "    :return: The normalized number\n",
    "    \"\"\"\n",
    "    nnum = 0\n",
    "    if num == 0:\n",
    "        return nnum\n",
    "    if num == np.nan:\n",
    "        return nnum\n",
    "    # if num >= 1 or num <= -1:\n",
    "    #     nnum = num / maxiumum\n",
    "    # else:\n",
    "    #     nnum = num * (1 / maxiumum)\n",
    "    nnum = (num - minimum) / (maximum - minimum)\n",
    "    return nnum\n",
    "\n",
    "\n",
    "def normalize_date(date: str, starting_date: str, ending_date: str, date_format: str) -> float:\n",
    "    \"\"\"\n",
    "    Return the position of the date between the starting and ending as a percentage\n",
    "    :param date: The date to format\n",
    "    :param starting_date: The lower date boundary\n",
    "    :param ending_date: The lower date boundary\n",
    "    :param date_format: The date format to use\n",
    "    :return: A float representing the positions between the date\n",
    "    \"\"\"\n",
    "    num_days = (datetime.strptime(ending_date, date_format) - datetime.strptime(starting_date, date_format)).days\n",
    "    day = (datetime.strptime(date, date_format) - datetime.strptime(starting_date, date_format)).days\n",
    "    return day / num_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gdelt(to_time_series=False):\n",
    "    print('Starting reading GDELT')\n",
    "    gdelt = list()\n",
    "    s3 = boto3.resource('s3')\n",
    "    gdelt_bucket = s3.Bucket('gdelt.4ibd.flo')\n",
    "    \n",
    "    for object_summary in gdelt_bucket.objects.filter(Prefix='normalized_gdelt_2008_2018.csv'):\n",
    "        if '.csv' in object_summary.key.split('/')[1]:\n",
    "            gdelt.append(pd.read_csv(f's3://gdelt.4ibd.flo/{object_summary.key}', compression='gzip',\n",
    "                                     engine='c', low_memory=True, na_values=[''], dtype=np.float32))\n",
    "    gdelt = pd.concat(gdelt, ignore_index=True)\n",
    "    gdelt.sort_values('date', inplace=True)\n",
    "    # print('GDELT Size :', gdelt.count())\n",
    "\n",
    "    print('Getting class Weight')\n",
    "    event_cols = [c for c in list(gdelt.columns) if 'event' in c]\n",
    "    wc = {i: gdelt[event_cols[i]].value_counts()[1] for i in range(len(event_cols))}\n",
    "    max_weight = max([nb_el for class_id, nb_el in wc.items()])\n",
    "    weight_classes = {class_id: max_weight / nb_el for class_id, nb_el in wc.items()}\n",
    "    \n",
    "    print('Divising in Train / Test set')\n",
    "    gdelt_train = gdelt[[c for c in list(gdelt.columns) if 'event' not in c]].values\n",
    "    gdelt_val = gdelt[[c for c in list(gdelt.columns) if 'event' in c]].values\n",
    "    train_num = int(len(gdelt) * 0.8)\n",
    "    \n",
    "    if to_time_series:\n",
    "        print('Reshaping to time series')\n",
    "        gdelt_train = np.reshape(gdelt_train, (-1, 16, 21))\n",
    "        gdelt_val = np.reshape(gdelt_val, (-1, 16, 220))\n",
    "        train_num = int(gdelt_train.shape[0] * 0.8)\n",
    "    \n",
    "    gdelt = {\n",
    "        'train': gdelt_train[:train_num],\n",
    "        'train_val': gdelt_val[:train_num],\n",
    "        'test': gdelt_train[train_num:],\n",
    "        'test_val': gdelt_val[train_num:],\n",
    "        'weight_classes' : weight_classes\n",
    "    }\n",
    "    return gdelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(input_shape: tuple, num_classes: int) -> Model:\n",
    "    \"\"\"\n",
    "    Regression model for The GDELT\n",
    "    :param input_shape: The input shape of the data\n",
    "    :param num_classes: The number of classes\n",
    "    :return: A compiled model\n",
    "    \"\"\"\n",
    "    print('Designing model')\n",
    "    inputs = Input(input_shape)\n",
    "    outputs = Dense(num_classes, activation='softmax')(inputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(input_shape: tuple, num_classes: int, neurons=256, layers=4, dr=0.3) -> Model:\n",
    "    \"\"\"\n",
    "    Regression model for The GDELT\n",
    "    :param input_shape: The input shape of the data\n",
    "    :param num_classes: The number of classes\n",
    "    :return: A compiled model\n",
    "    \"\"\"\n",
    "    print('Designing model')\n",
    "    inputs = Input(input_shape)\n",
    "    linear = Dense(neurons, activation='relu')(inputs)\n",
    "    linear = BatchNormalization()(linear)\n",
    "    linear = Dropout(dr)(linear)\n",
    "    for _ in range(1, layers):\n",
    "        linear = Dense(neurons, activation='relu')(linear)\n",
    "        linear = BatchNormalization()(linear)\n",
    "        linear = Dropout(dr)(linear)\n",
    "    outputs = Dense(num_classes, activation='softmax')(linear)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(input_shape: tuple, num_classes: int, neurons=256, layers=4, dr=0.3) -> Model:\n",
    "    print('Designing model')\n",
    "    inputs = Input(input_shape)\n",
    "    lstm = LSTM(neurons, activation='relu', dropout=dr, return_sequences=True)(inputs)\n",
    "    lstm = BatchNormalization()(lstm)\n",
    "    for _ in range(1, layers):\n",
    "        lstm = LSTM(neurons, activation='relu', dropout=dr, return_sequences=True)(lstm)\n",
    "        lstm = BatchNormalization()(lstm)\n",
    "    outputs = TimeDistributed(Dense(num_classes, activation='softmax'))(lstm)\n",
    "    # outputs = LSTM(num_classes, activation='softmax', return_sequences=True)(lstm)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting reading GDELT\n",
      "Getting class Weight\n",
      "Divising in Train / Test set\n",
      "Reshaping to time series\n"
     ]
    }
   ],
   "source": [
    "gdelt = read_gdelt(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'LSTM_2D256_MODEL_ADAM_CAT_DR_BN'\n",
    "batch_size = 16384\n",
    "nb_epochs = 128\n",
    "num_classes = gdelt['train_val'].shape[1:][1]\n",
    "shape = gdelt['train'].shape[1:]\n",
    "csv_logger = CSVLogger(f'./{experiment_name}.csv')\n",
    "checkpoint = ModelCheckpoint(f'./{experiment_name}.h5', monitor='val_categorical_accuracy',\n",
    "                             verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Starting learning')\n",
    "gdelt_model = lstm_model(shape, num_classes, 256, 2, 0.25)  # lstm_model(shape, num_classes, 512)\n",
    "gdelt_model.fit(gdelt['train'], gdelt['train_val'], batch_size=batch_size, epochs=nb_epochs,\n",
    "                shuffle=True, validation_data=(gdelt['test'], gdelt['test_val']), callbacks=[csv_logger, checkpoint])\n",
    "                # class_weight=gdelt['weight_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing to S3')\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
