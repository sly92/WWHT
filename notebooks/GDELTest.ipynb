{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for sample Weight\n",
    "# Test With LSTM\n",
    "# Test with shuffle false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from datetime import datetime\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.keras._impl.keras.layers import Dense, Input, LSTM, BatchNormalization, Flatten, TimeDistributed, Dropout, Reshape\n",
    "from tensorflow.python.keras._impl.keras.models import Model\n",
    "from tensorflow.python.keras._impl.keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_divisor(num: int) -> list:\n",
    "    \"\"\"\n",
    "    Return all the divisors of a number\n",
    "    :param num: The number to find the divisors\n",
    "    :return: A list of divisors\n",
    "    \"\"\"\n",
    "    divisor = list()\n",
    "    for i in range(1, num+1):\n",
    "        if num % i == 0:\n",
    "            divisor.append(i)\n",
    "    return divisor\n",
    "\n",
    "\n",
    "def normalize_nums(num: int, minimum: int, maximum: int) -> float:\n",
    "    \"\"\"\n",
    "    Normalize a positive integer between 0 and 1\n",
    "    :param num: The num to normalize\n",
    "    :param minimum: The maximum range\n",
    "    :param maximum:  The minimum range\n",
    "    :return: The normalized number\n",
    "    \"\"\"\n",
    "    nnum = 0\n",
    "    if num == 0:\n",
    "        return nnum\n",
    "    if num == np.nan:\n",
    "        return nnum\n",
    "    # if num >= 1 or num <= -1:\n",
    "    #     nnum = num / maxiumum\n",
    "    # else:\n",
    "    #     nnum = num * (1 / maxiumum)\n",
    "    nnum = (num - minimum) / (maximum - minimum)\n",
    "    return nnum\n",
    "\n",
    "\n",
    "def normalize_date(date: str, starting_date: str, ending_date: str, date_format: str) -> float:\n",
    "    \"\"\"\n",
    "    Return the position of the date between the starting and ending as a percentage\n",
    "    :param date: The date to format\n",
    "    :param starting_date: The lower date boundary\n",
    "    :param ending_date: The lower date boundary\n",
    "    :param date_format: The date format to use\n",
    "    :return: A float representing the positions between the date\n",
    "    \"\"\"\n",
    "    num_days = (datetime.strptime(ending_date, date_format) - datetime.strptime(starting_date, date_format)).days\n",
    "    day = (datetime.strptime(date, date_format) - datetime.strptime(starting_date, date_format)).days\n",
    "    return day / num_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gdelt(to_time_series=False):\n",
    "    print('Starting reading GDELT')\n",
    "    gdelt = list()\n",
    "    s3 = boto3.resource('s3')\n",
    "    gdelt_bucket = s3.Bucket('gdelt.4ibd.flo')\n",
    "    \n",
    "    for object_summary in gdelt_bucket.objects.filter(Prefix='normalized_gdelt_2008_2018.csv'):\n",
    "        if '.csv' in object_summary.key.split('/')[1]:\n",
    "            gdelt.append(pd.read_csv(f's3://gdelt.4ibd.flo/{object_summary.key}', compression='gzip',\n",
    "                                     engine='c', low_memory=True, na_values=[''], dtype=np.float32))\n",
    "    gdelt = pd.concat(gdelt, ignore_index=True)\n",
    "    gdelt.sort_values('date', inplace=True)\n",
    "    # print('GDELT Size :', gdelt.count())\n",
    "\n",
    "    print('Getting class Weight')\n",
    "    event_cols = [c for c in list(gdelt.columns) if 'event' in c]\n",
    "    wc = {i: gdelt[event_cols[i]].value_counts()[1] for i in range(len(event_cols))}\n",
    "    max_weight = max([nb_el for class_id, nb_el in wc.items()])\n",
    "    weight_classes = {class_id: max_weight / nb_el for class_id, nb_el in wc.items()}\n",
    "    \n",
    "    print('Divising in Train / Test set')\n",
    "    gdelt_train = gdelt[[c for c in list(gdelt.columns) if 'event' not in c]].values\n",
    "    gdelt_val = gdelt[[c for c in list(gdelt.columns) if 'event' in c]].values\n",
    "    \n",
    "    train_num = int(len(gdelt) * 0.8)\n",
    "    gdelt = {\n",
    "        'train': gdelt_train[:train_num],\n",
    "        'train_val': gdelt_val[:train_num],\n",
    "        'test': gdelt_train[train_num:],\n",
    "        'test_val': gdelt_val[train_num:],\n",
    "        'weight_classes' : weight_classes\n",
    "    }\n",
    "    return gdelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(input_shape: tuple, num_classes: int) -> Model:\n",
    "    \"\"\"\n",
    "    Regression model for The GDELT\n",
    "    :param input_shape: The input shape of the data\n",
    "    :param num_classes: The number of classes\n",
    "    :return: A compiled model\n",
    "    \"\"\"\n",
    "    print('Designing model')\n",
    "    inputs = Input(input_shape)\n",
    "    outputs = Dense(num_classes, activation='softmax')(inputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(input_shape: tuple, num_classes: int, neurons=256, layers=4, dr=0.3) -> Model:\n",
    "    \"\"\"\n",
    "    Regression model for The GDELT\n",
    "    :param input_shape: The input shape of the data\n",
    "    :param num_classes: The number of classes\n",
    "    :return: A compiled model\n",
    "    \"\"\"\n",
    "    print('Designing model')\n",
    "    inputs = Input(input_shape)\n",
    "    linear = Dense(neurons, activation='relu')(inputs)\n",
    "    linear = BatchNormalization()(linear)\n",
    "    linear = Dropout(dr)(linear)\n",
    "    for _ in range(1, layers):\n",
    "        linear = Dense(neurons, activation='relu')(linear)\n",
    "        linear = BatchNormalization()(linear)\n",
    "        linear = Dropout(dr)(linear)\n",
    "    outputs = Dense(num_classes, activation='softmax')(linear)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(input_shape: tuple, num_classes: int, neurons=256, layers=4, dr=0.3) -> Model:\n",
    "    print('Designing model')\n",
    "    inputs = Input(input_shape)\n",
    "    lstm = LSTM(neurons, activation='relu', dropout=dr)(inputs)\n",
    "    lstm = BatchNormalization()(lstm)\n",
    "    for _ in range(1, layers):\n",
    "        lstm = LSTM(neurons, activation='relu', dropout=dr)(lstm)\n",
    "        lstm = BatchNormalization()(lstm)\n",
    "    outputs = Dense(num_classes, activation='softmax')(lstm)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting reading GDELT\n",
      "Getting class Weight\n",
      "Divising in Train / Test set\n"
     ]
    }
   ],
   "source": [
    "gdelt = read_gdelt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'LINEAR_4D512_MODEL_ADAM_CAT_DR_BN'\n",
    "batch_size = 16384\n",
    "nb_epochs = 128\n",
    "num_classes = gdelt['train_val'].shape[1:][0]\n",
    "shape = gdelt['train'].shape[1:]\n",
    "csv_logger = CSVLogger(f'./{experiment_name}.csv')\n",
    "checkpoint = ModelCheckpoint(f'./{experiment_name}.h5', monitor='val_categorical_accuracy',\n",
    "                             verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting learning\n",
      "Designing model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               11264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 220)               112860    \n",
      "=================================================================\n",
      "Total params: 920,284\n",
      "Trainable params: 916,188\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 151129 samples, validate on 37783 samples\n",
      "Epoch 1/128\n",
      "151129/151129 [==============================] - 13s 85us/step - loss: 113.2446 - categorical_accuracy: 0.0048 - val_loss: 5.3934 - val_categorical_accuracy: 0.0027\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.00273, saving model to ./LINEAR_4D512_MODEL_ADAM_CAT_DR_BN.h5\n",
      "Epoch 2/128\n",
      "151129/151129 [==============================] - 14s 89us/step - loss: 104.0098 - categorical_accuracy: 0.0040 - val_loss: 5.4184 - val_categorical_accuracy: 4.7640e-04\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve\n",
      "Epoch 3/128\n",
      "151129/151129 [==============================] - 16s 107us/step - loss: 101.2744 - categorical_accuracy: 0.0035 - val_loss: 5.4552 - val_categorical_accuracy: 1.8527e-04\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve\n",
      "Epoch 4/128\n",
      "151129/151129 [==============================] - 17s 115us/step - loss: 96.6359 - categorical_accuracy: 0.0038 - val_loss: 5.4879 - val_categorical_accuracy: 1.0587e-04\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve\n",
      "Epoch 5/128\n",
      "151129/151129 [==============================] - 18s 122us/step - loss: 96.6691 - categorical_accuracy: 0.0035 - val_loss: 5.5135 - val_categorical_accuracy: 1.0587e-04\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve\n",
      "Epoch 6/128\n",
      "151129/151129 [==============================] - 17s 110us/step - loss: 95.4662 - categorical_accuracy: 0.0038 - val_loss: 5.5350 - val_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve\n",
      "Epoch 7/128\n",
      "151129/151129 [==============================] - 16s 109us/step - loss: 94.1177 - categorical_accuracy: 0.0035 - val_loss: 5.5628 - val_categorical_accuracy: 7.9401e-05\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve\n",
      "Epoch 8/128\n",
      "151129/151129 [==============================] - 19s 125us/step - loss: 93.7469 - categorical_accuracy: 0.0037 - val_loss: 5.5970 - val_categorical_accuracy: 2.6467e-05\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve\n",
      "Epoch 9/128\n",
      " 16384/151129 [==>...........................] - ETA: 13s - loss: 93.5765 - categorical_accuracy: 0.0033"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3bf202d85187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m gdelt_model.fit(gdelt['train'], gdelt['train_val'], batch_size=batch_size, epochs=nb_epochs,\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdelt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdelt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 class_weight=gdelt['weight_classes'])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m     updated = session.run(\n\u001b[0;32m-> 2824\u001b[0;31m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2825\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 123, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "print('Starting learning')\n",
    "gdelt_model = linear_model(shape, num_classes, 512)  # regression_model(shape, num_classes)\n",
    "gdelt_model.fit(gdelt['train'], gdelt['train_val'], batch_size=batch_size, epochs=nb_epochs,\n",
    "                shuffle=True, validation_data=(gdelt['test'], gdelt['test_val']), callbacks=[csv_logger, checkpoint],\n",
    "                class_weight=gdelt['weight_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing to S3')\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
